{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install langchain\n",
    "# !pip install python-dotenv\n",
    "# !pip install pypdf\n",
    "# !pip install chromadb\n",
    "# !pip install sentence-transformers\n",
    "# !pip install openai\n",
    "# !pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API token * key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] \n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "# print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceBgeEmbeddings,\n",
    ")\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "* pdf에서 텍스트 추출\n",
    "* 취소선과 겹치는 문장의 경우 < del>  <> 이런식으로 처리\n",
    "* '. .' 과 같은 불필요한 단어 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "\n",
    "def find_text_by_red_strikethrough_status(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    strikethrough_texts = []\n",
    "    non_strikethrough_texts = []\n",
    "    full_texts = []\n",
    "\n",
    "    for page_number in range(len(document)):\n",
    "        page = document[page_number]\n",
    "        words = page.get_text(\"words\")  # 단어와 그 위치를 반환\n",
    "        paths = page.get_drawings()  # 페이지의 그래픽 요소를 추출\n",
    "\n",
    "        strikethrough_lines = []\n",
    "\n",
    "        # 그림 요소 중에서 선과 사각형을 검사하여 빨간색 취소선으로 판단\n",
    "        for path in paths:\n",
    "            color = path[\"color\"]\n",
    "            # 선의 색상이 빨간색인 경우에만 처리\n",
    "            if color == (1, 0, 0):  # RGB 색상으로 빨간색 확인\n",
    "                for item in path[\"items\"]:\n",
    "                    if item[0] == \"l\":  # 선인 경우\n",
    "                        p1, p2 = item[1:]\n",
    "                        if p1.y == p2.y:  # 수평선이면\n",
    "                            rect = fitz.Rect(p1.x, p1.y - 1, p2.x, p2.y + 1)\n",
    "                            strikethrough_lines.append(rect)\n",
    "                    elif item[0] == \"re\":  # 사각형인 경우\n",
    "                        rect = item[1]\n",
    "                        if rect.width > rect.height and rect.height < 3:  # 넓이가 높이보다 많이 크고 높이가 3pt 이하이면\n",
    "                            strikethrough_lines.append(rect)\n",
    "\n",
    "        # 각 단어와 취소선이 겹치는지 검사\n",
    "        same_line = words[0][5]\n",
    "        previous_strike = False\n",
    "        strike_line = ''\n",
    "        line = ''\n",
    "        for word in words:\n",
    "            word_rect = fitz.Rect(word[:4])  # 단어의 위치\n",
    "            strikethrough_found = False\n",
    "            for line_rect in strikethrough_lines:\n",
    "                if word_rect.intersects(line_rect):  # 겹치면\n",
    "                    strikethrough_found = True\n",
    "                    break\n",
    "            if not strikethrough_found:  # 취소선이 없으면\n",
    "                non_strikethrough_texts.append(word[4:6])  # 취소선이 적용되지 않은 단어 추가\n",
    "                if same_line != word[5]:\n",
    "                    same_line = word[5]\n",
    "                    line += '\\n'\n",
    "\n",
    "                line = line + ' ' + word[4]\n",
    "                \n",
    "                if strikethrough_found != previous_strike:\n",
    "                    full_texts.append('<del>' + strike_line + '<>')\n",
    "                    strike_line = ''\n",
    "                previous_strike = False\n",
    "            else:\n",
    "                strikethrough_texts.append(word[4:6])  # 취소선이 적용된 단어 추가\n",
    "                strike_line = strike_line  + ' ' + word[4]\n",
    "                if strikethrough_found != previous_strike:\n",
    "                    full_texts.append(line + '\\n')\n",
    "                    line=''\n",
    "                previous_strike = True\n",
    "        full_texts.append(line)\n",
    "    document.close()\n",
    "    return strikethrough_texts, non_strikethrough_texts, full_texts\n",
    "\n",
    "def re_text(full_texts):\n",
    "    full = ''\n",
    "    for text in full_texts:\n",
    "        cleaned_text = re.sub(r'\\.\\s*\\.', '', text)\n",
    "        full += cleaned_text\n",
    "    return full\n",
    "\n",
    "pdf_path = ['real_data_ex.pdf', 'real_data_ex2.pdf']\n",
    "docs = []\n",
    "for pdf in pdf_path:\n",
    "    strikethrough_texts, non_strikethrough_texts, full_texts = find_text_by_red_strikethrough_status(pdf)\n",
    "    texts = re_text(full_texts)\n",
    "    docs.append((pdf, texts))\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make chunk data - vector db에 저장하기전 데이터 만들기\n",
    "\n",
    "* 앞서 pdf에서 추출한 데이터 활용\n",
    "* vector DB에 저장하기 위해 pdf를 chunk 단위로 잘라 저장할 필요가 있음\n",
    "* RecursiveCharacterTextSplitter를 이용하여 2000개씩 자르고, 200개씩 겹쳐서 문서가 연결되게끔 split\n",
    "    * ex) \"나는 ai 파트를 맡고\", \"ai 파트를 맡고 있어요\" -> 이런식으로 겹쳐서 저장\n",
    "\n",
    "* 메타데이터로 pdf 문서 이름을 같이 저장\n",
    "* create_document를 이용해서 2000개로 자른 텍스트와 메타데이터 저장\n",
    "    * Document(page_content='< del>  <> 1 주의 금액 400원  , metadata={'source': 'real_data_ex.pdf'}) 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "data = []\n",
    "for pdf, texts in docs:\n",
    "    split_texts = text_splitter.split_text(texts)\n",
    "    metadata = [{'source': pdf}] * len(split_texts)\n",
    "    pages = text_splitter.create_documents(split_texts, metadatas=metadata)\n",
    "    data.append(pages)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data to vector DB\n",
    "* vector db에 저장하기 위한 임베딩은 openai의 임베딩을 사용\n",
    "* 앞서 Document(page_content, metadata) 형식의 데이터를 db에 저장\n",
    "* persist_directory는 로컬에 저장할 폴더 이름\n",
    "* vector_index._collection.count()로 현재 DB에 몇 개의 Document가 저장되어 있는지 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings.sentence_transformer import (\n",
    "#     SentenceTransformerEmbeddings,\n",
    "# )\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# # directory = 'chroma_store_hugging'\n",
    "# directory = 'chroma_store_open'\n",
    "\n",
    "# # embeddings = HuggingFaceEmbeddings()\n",
    "# # embeddings_model = HuggingFaceEmbeddings(\n",
    "# #     model_name='jhgan/ko-sbert-nli',\n",
    "# #     model_kwargs={'device':'cpu'},\n",
    "# #     encode_kwargs={'normalize_embeddings':True},\n",
    "# # )\n",
    "\n",
    "# embeddings_open = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# for pages in data:\n",
    "#     vector_index = Chroma.from_documents(\n",
    "#         pages, # Documents\n",
    "#         embedding = embeddings_open, # Text embedding model\n",
    "#         persist_directory=directory # persists the vectors to the file system\n",
    "#         )\n",
    "# # vector_index.persist()\n",
    "# print('count: ', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all data\n",
    "* db에 있는 정보 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 정보 삭제\n",
    "# ids = vector_index.get(0)['ids']\n",
    "\n",
    "# print('before: ', vector_index._collection.count())\n",
    "# for i in ids:\n",
    "#     vector_index._collection.delete(ids=i)\n",
    "# print('after :', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "* db에 따로 저장하지 않고 저장되어 있는 것만 사용할 경우 load 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_open = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_index = Chroma(persist_directory='chroma_store_open', embedding_function=embeddings_open)\n",
    "print('count: ', vector_index._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface model (prompt)\n",
    "* huggingface model(llm)을 사용\n",
    "    * prompt는 영어로 작성된 prompt 사용 - prompt에 따라 성능이 달라짐\n",
    "    * retriever는 벡터 DB에서 내가 질문한 것과 유사도가 높은 Document를 k개 고른다.\n",
    "    * ConversationalRetrievalChain으로 llm, retriever, prompt를 사용\n",
    "    * 물어보는 질문에 대해 db에서 유사한 Document를 찾고 그것을 기반으로 답변 생성\n",
    "    * chat_history에 답변 저장\n",
    "\n",
    "* 만약 openai 모델을 사용한다면 prompt는 한국어로 작성해도 괜찮다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_history = []\n",
    "####################retriever######################\n",
    "pdfs_info = ''\n",
    "for i in pdf_path:\n",
    "    pdfs_info += \"'\" + i + \"', \"\n",
    "pdfs_info\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The company the chunk is from, should be one of \" + pdfs_info,\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "document_content_description = \"company information\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_index,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    search_kwargs={\n",
    "        \"k\": 5, # Select top k search results\n",
    "    } \n",
    ")\n",
    "\n",
    "# retriever = vector_index.as_retriever(\n",
    "#     search_type=\"similarity\", # Cosine Similarity\n",
    "#     search_kwargs={\n",
    "#         \"k\": 5, # Select top k search results\n",
    "#     } \n",
    "# )\n",
    "\n",
    "###################################################\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, \n",
    "    max_new_tokens=2048,  \n",
    "    temperature=0.1, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()], \n",
    "    streaming=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"real_data_ex문서에서 상호의 영어명, 본점, 액면가, 발행한 주식의 총수, 발행할 주식의 총수, 회사성립연월일, 등기번호, 등록번호에 대해 정리해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################prompt######################\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    you must not use information in the form of <del><> except when requested\n",
    "    The metadata being different means the documents are different. \n",
    "    I want to obtain information seperately for each document.\n",
    "    you answer me only using context for question:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Question: {question}\n",
    "    The answer should be in Korean only\"\"\")\n",
    "\n",
    "\n",
    "conv_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    retriever=retriever,\n",
    "    # chain_type=\"stuff\", \n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "query_list = [\"real_data_ex문서에서 상호의 영어명, 본점, 액면가, 발행한 주식의 총수, 발행할 주식의 총수, 회사성립연월일, 등기번호, 등록번호에 대해 정리해줘\"]\n",
    "for query in query_list:\n",
    "    ## open ai\n",
    "    # result_open = conv_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
    "    # print(result_open)\n",
    "    # chat_history.append((query, result_open[\"answer\"]))\n",
    "    \n",
    "    ##  hugging face\n",
    "    result = conv_chain.invoke({\"question\": query})\n",
    "    print()\n",
    "    chat_history = memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"real_data_ex2에서 설립시 액면가는?\"\n",
    "result = conv_chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
